{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "627d5547-04e1-433e-aea6-50ee050c94f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"preguntas_respuestas.csv\"\n",
    "OUTPUT_DIR = \"datos_fine_tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2eedb779-0367-4f0e-b451-c1b83d7655f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "\n",
    "def calculate_optimal_split(total_records):\n",
    "    if total_records < 1000:\n",
    "        train_size = 0.85\n",
    "        val_size = 0.10\n",
    "        test_size = 0.05\n",
    "    elif total_records < 10000:\n",
    "        train_size = 0.80\n",
    "        val_size = 0.10\n",
    "        test_size = 0.10\n",
    "    else:\n",
    "        train_size = 0.90\n",
    "        val_size = 0.05\n",
    "        test_size = 0.05\n",
    "    \n",
    "    min_val_test = 100  # mínimo de registros para val y test\n",
    "    \n",
    "    # Ajustar si los conjuntos de val/test son muy pequeños\n",
    "    val_records = math.floor(total_records * val_size)\n",
    "    test_records = math.floor(total_records * test_size)\n",
    "    \n",
    "    if val_records < min_val_test or test_records < min_val_test:\n",
    "        required_total = min_val_test * 2  # para val y test\n",
    "        if required_total < total_records:\n",
    "            # Recalcular proporciones manteniendo mínimos\n",
    "            val_size = test_size = min_val_test / total_records\n",
    "            train_size = 1 - (val_size + test_size)\n",
    "    \n",
    "    return train_size, val_size, test_size\n",
    "\n",
    "def save_to_jsonl(df, filename):\n",
    "        filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "            for _, row in df.iterrows():\n",
    "                json_record = row.to_dict()\n",
    "                f.write(json.dumps(json_record, ensure_ascii=False) + '\\n')\n",
    "        print(f\"✓ Generado: {filename} ({len(df)} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ada622-855f-4afd-9580-870ae70baba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57172ac-1d23-4b31-bd91-ae76f8a8e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "total_records = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da3b4488-9fb2-4c90-a56d-44149e72b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size, test_size = calculate_optimal_split(total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "096bb35b-e365-412c-8e77-c9c6c32920bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Análisis del dataset:\n",
      "Total de registros: 803\n",
      "\n",
      "Proporciones calculadas automáticamente:\n",
      "Training:   75.1% (603 registros)\n",
      "Validation: 12.5% (100 registros)\n",
      "Testing:    12.5% (100 registros)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAnálisis del dataset:\")\n",
    "print(f\"Total de registros: {total_records}\")\n",
    "print(\"\\nProporciones calculadas automáticamente:\")\n",
    "print(f\"Training:   {train_size*100:.1f}% ({math.floor(total_records*train_size)} registros)\")\n",
    "print(f\"Validation: {val_size*100:.1f}% ({math.floor(total_records*val_size)} registros)\")\n",
    "print(f\"Testing:    {test_size*100:.1f}% ({math.floor(total_records*test_size)} registros)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fde4058e-d271-4a9d-b8e0-148145235f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera división: separar el conjunto de entrenamiento\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(\n",
    "        df, \n",
    "        train_size=train_size,\n",
    "        random_state=42,\n",
    "        shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67628423-e3e1-47f8-87ca-f25c22a630fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda división: separar validación y prueba del resto\n",
    "val_size_adjusted = val_size / (val_size + test_size)\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    train_size=val_size_adjusted,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa594284-f5f8-43db-b28d-064dbe6feddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generando archivos JSONL...\n",
      "✓ Generado: train.jsonl (603 registros)\n",
      "✓ Generado: valid.jsonl (100 registros)\n",
      "✓ Generado: test.jsonl (100 registros)\n"
     ]
    }
   ],
   "source": [
    "# Función auxiliar para guardar en formato JSONL\n",
    "print(\"\\nGenerando archivos JSONL...\")\n",
    "save_to_jsonl(train_df, 'train.jsonl')\n",
    "save_to_jsonl(val_df, 'valid.jsonl')\n",
    "save_to_jsonl(test_df, 'test.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
